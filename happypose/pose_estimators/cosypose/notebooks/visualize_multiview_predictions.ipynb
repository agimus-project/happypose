{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from cosypose.config import LOCAL_DATA_DIR\n",
    "from cosypose.datasets.datasets_cfg import make_scene_dataset\n",
    "from cosypose.rendering.bullet_scene_renderer import BulletSceneRenderer\n",
    "from cosypose.datasets.wrappers.multiview_wrapper import MultiViewWrapper\n",
    "from cosypose.visualization.multiview import make_cosypose_plots, render_candidates, filter_predictions, get_group_infos\n",
    "from cosypose.visualization.multiview import make_scene_renderings\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from bokeh.io import show, output_notebook; output_notebook()\n",
    "from bokeh.plotting import gridplot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load results: Choose dataset, result_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment/uncomment (shortcut ctrl+:) blocks of code under each dataset to choose a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = LOCAL_DATA_DIR / 'results'\n",
    "\n",
    "# YCB-Video\n",
    "# result_id = 'ycbv-n_views=5--8073381555'\n",
    "# n_views = 5\n",
    "\n",
    "# scene_ds_name = 'ycbv.test.keyframes'\n",
    "# det_prefix = 'posecnn_init'\n",
    "# urdf_ds_name = 'ycbv'\n",
    "\n",
    "# T-LESS\n",
    "result_id = 'tless-vivo-n_views=8--2322743008'\n",
    "n_views = 8\n",
    "scene_ds_name = 'tless.primesense.test.bop19'\n",
    "det_prefix = 'pix2pose_detections'\n",
    "urdf_ds_name = 'tless.cad'\n",
    "colormap_rgb = None\n",
    "\n",
    "results = torch.load(results_dir / result_id / 'results.pth.tar')\n",
    "\n",
    "scene_ds = make_scene_dataset(scene_ds_name)\n",
    "mv_scene_ds = MultiViewWrapper(scene_ds, n_views)\n",
    "\n",
    "dict_preds = dict()\n",
    "for k in ('cand_inputs', 'cand_matched', 'ba_output'):\n",
    "    dict_preds[k] = results['predictions'][f'{det_prefix}/{k}']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose the group of views for which we want to plot predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the group ids that correspond to a scene. You can use this to choose a group id if you want to look at a scene in particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YCB-Video\n",
    "# scene_id = 55\n",
    "\n",
    "# TLESS\n",
    "scene_id = 16\n",
    "\n",
    "objects = results['predictions'][f'{det_prefix}/scene/objects']\n",
    "cameras = results['predictions'][f'{det_prefix}/scene/cameras']\n",
    "print(f\"{scene_ds_name} scene {scene_id} has groups: \", np.unique(objects.infos.loc[:, ['scene_id', 'group_id']].set_index('scene_id').loc[scene_id]['group_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example YCB-Video\n",
    "# group_id = 334\n",
    "\n",
    "# Example on T-LESS\n",
    "group_id = 105\n",
    "\n",
    "scene_id, view_ids = get_group_infos(group_id, mv_scene_ds)\n",
    "print(f'Making plots for group_id={group_id} (scene_id={scene_id}, view_ids={view_ids}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot input images / detections / candidates with marked inliers / scene reconstructed / ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: two distincts objects may have the same color due to the limited size of the color palette\n",
    "n_views_to_plot = 4\n",
    "renderer = BulletSceneRenderer(urdf_ds_name)\n",
    "fig_array = make_cosypose_plots(\n",
    "    scene_ds,\n",
    "    scene_id=scene_id, \n",
    "    view_ids=view_ids[:n_views_to_plot],\n",
    "    dict_predictions=dict_preds,\n",
    "    renderer=renderer,\n",
    "    use_class_colors_for_3d='ycbv' not in scene_ds_name,\n",
    "    outlier_color=(1, 1, 1)\n",
    ")\n",
    "renderer.disconnect()\n",
    "\n",
    "show(gridplot(fig_array, sizing_mode='scale_width'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make visualization GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: colors aren't supposed to match the ones from the plots above.\n",
    "objects = results['predictions'][f'{det_prefix}/scene/objects']\n",
    "cameras = results['predictions'][f'{det_prefix}/scene/cameras']\n",
    "objects_, cameras_ = filter_predictions(objects, group_id), filter_predictions(cameras, group_id)\n",
    "\n",
    "fps = 25\n",
    "duration = 10\n",
    "n_images = fps * duration\n",
    "# n_images = 1  # Uncomment this if you just want to look at one image, generating the gif takes some time\n",
    "images = make_scene_renderings(objects_, cameras_,\n",
    "                               urdf_ds_name=urdf_ds_name, \n",
    "                               distance=1.3, object_scale=2.0,\n",
    "                               show_cameras=False, camera_color=(0, 0, 0, 1),\n",
    "                               theta=np.pi/4, resolution=(640, 480),\n",
    "                               object_id_ref=0, \n",
    "                               colormap_rgb=defaultdict(lambda: [1, 1, 1, 1]) if 'ycb' in scene_ds_name else None,\n",
    "                               angles=np.linspace(0, 2*np.pi, n_images))\n",
    "save_path = f'gifs/scene_ds={scene_ds_name}-scene={scene_id}-nviews={n_views}-scene_group={group_id}.gif'\n",
    "print(f\"Save location: {Path(save_path).resolve()}\")\n",
    "imageio.mimsave(save_path, images, fps=fps)\n",
    "plt.imshow(images[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosypose",
   "language": "python",
   "name": "cosypose"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
